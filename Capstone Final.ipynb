{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.3\n",
      "  latest version: 4.8.4\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  added / updated specs:\n",
      "    - folium=0.5.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    altair-4.1.0               |             py_1         614 KB  conda-forge\n",
      "    attrs-20.1.0               |     pyh9f0ad1d_0          41 KB  conda-forge\n",
      "    branca-0.4.1               |             py_0          26 KB  conda-forge\n",
      "    brotlipy-0.7.0             |py36h8c4c3a4_1000         346 KB  conda-forge\n",
      "    chardet-3.0.4              |py36h9f0ad1d_1006         188 KB  conda-forge\n",
      "    cryptography-3.1           |   py36h45558ae_0         615 KB  conda-forge\n",
      "    folium-0.5.0               |             py_0          45 KB  conda-forge\n",
      "    openssl-1.1.1g             |       h516909a_1         2.1 MB  conda-forge\n",
      "    pandas-1.1.1               |   py36h831f99a_0        10.5 MB  conda-forge\n",
      "    pysocks-1.7.1              |   py36h9f0ad1d_1          27 KB  conda-forge\n",
      "    toolz-0.10.0               |             py_0          46 KB  conda-forge\n",
      "    vincent-0.4.4              |             py_1          28 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        14.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  altair             conda-forge/noarch::altair-4.1.0-py_1\n",
      "  attrs              conda-forge/noarch::attrs-20.1.0-pyh9f0ad1d_0\n",
      "  branca             conda-forge/noarch::branca-0.4.1-py_0\n",
      "  brotlipy           conda-forge/linux-64::brotlipy-0.7.0-py36h8c4c3a4_1000\n",
      "  chardet            conda-forge/linux-64::chardet-3.0.4-py36h9f0ad1d_1006\n",
      "  cryptography       conda-forge/linux-64::cryptography-3.1-py36h45558ae_0\n",
      "  entrypoints        conda-forge/linux-64::entrypoints-0.3-py36h9f0ad1d_1001\n",
      "  folium             conda-forge/noarch::folium-0.5.0-py_0\n",
      "  idna               conda-forge/noarch::idna-2.10-pyh9f0ad1d_0\n",
      "  importlib_metadata conda-forge/noarch::importlib_metadata-1.7.0-0\n",
      "  jinja2             conda-forge/noarch::jinja2-2.11.2-pyh9f0ad1d_0\n",
      "  jsonschema         conda-forge/linux-64::jsonschema-3.2.0-py36h9f0ad1d_1\n",
      "  markupsafe         conda-forge/linux-64::markupsafe-1.1.1-py36h8c4c3a4_1\n",
      "  pandas             conda-forge/linux-64::pandas-1.1.1-py36h831f99a_0\n",
      "  pyopenssl          conda-forge/noarch::pyopenssl-19.1.0-py_1\n",
      "  pyrsistent         conda-forge/linux-64::pyrsistent-0.16.0-py36h8c4c3a4_0\n",
      "  pysocks            conda-forge/linux-64::pysocks-1.7.1-py36h9f0ad1d_1\n",
      "  pytz               conda-forge/noarch::pytz-2020.1-pyh9f0ad1d_0\n",
      "  requests           conda-forge/noarch::requests-2.24.0-pyh9f0ad1d_0\n",
      "  toolz              conda-forge/noarch::toolz-0.10.0-py_0\n",
      "  urllib3            conda-forge/noarch::urllib3-1.25.10-py_0\n",
      "  vincent            conda-forge/noarch::vincent-0.4.4-py_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  openssl                                 1.1.1g-h516909a_0 --> 1.1.1g-h516909a_1\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pysocks-1.7.1        | 27 KB     | ##################################### | 100% \n",
      "toolz-0.10.0         | 46 KB     | ##################################### | 100% \n",
      "chardet-3.0.4        | 188 KB    | ##################################### | 100% \n",
      "pandas-1.1.1         | 10.5 MB   | ##################################### | 100% \n",
      "folium-0.5.0         | 45 KB     | ##################################### | 100% \n",
      "attrs-20.1.0         | 41 KB     | ##################################### | 100% \n",
      "cryptography-3.1     | 615 KB    | ##################################### | 100% \n",
      "branca-0.4.1         | 26 KB     | ##################################### | 100% \n",
      "brotlipy-0.7.0       | 346 KB    | ##################################### | 100% \n",
      "openssl-1.1.1g       | 2.1 MB    | ##################################### | 100% \n",
      "altair-4.1.0         | 614 KB    | ##################################### | 100% \n",
      "vincent-0.4.4        | 28 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Packages installed. Go gettem.\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge folium=0.5.0 --yes\n",
    "print('Packages installed. Go gettem.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.cluster import KMeans\n",
    "import folium \n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (4.5.2)\n",
      "lxml is installed I promise not to ask you to install it again\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('lxml is installed I promise not to ask you to install it again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "lxml not found, please install it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7ac50feff5f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_euro_cities_wiki\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://en.wikipedia.org/wiki/List_of_European_cities_by_population_within_city_limits\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwiki_dfdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_euro_cities_wiki\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2011 Eurostatpopulation[1]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Image'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Ref.'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwiki_dfdrop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"City\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Istanbul\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.6/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0mkeep_default_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_default_na\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m         \u001b[0mdisplayed_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplayed_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m     )\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.6/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0mretained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mflav\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflavor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiled_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplayed_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.6/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parser_dispatch\u001b[0;34m(flavor)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_HAS_LXML\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lxml not found, please install it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_valid_parsers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflavor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: lxml not found, please install it"
     ]
    }
   ],
   "source": [
    "df_euro_cities_wiki=pd.read_html(\"https://en.wikipedia.org/wiki/List_of_European_cities_by_population_within_city_limits\")[0]\n",
    "\n",
    "wiki_dfdrop=df_euro_cities_wiki.drop(columns=['Unnamed: 0', 'Date', '2011 Eurostatpopulation[1]', 'Image', 'Ref.'])\n",
    "\n",
    "wiki_dfdrop[\"City\"][0] = \"Istanbul\"\n",
    "wiki_dfdrop[\"City\"][1] = \"Moscow\"\n",
    "wiki_dfdrop[\"Officialpopulation\"][0] = \"15519267\"\n",
    "wiki_dfdrop=wiki_dfdrop.rename(columns={'Officialpopulation': 'Official Population'})\n",
    "\n",
    "df_bigcities=wiki_dfdrop.head(15)\n",
    "\n",
    "discard = []\n",
    "keep = []\n",
    "\n",
    "for row in df_bigcities['Location']:\n",
    "    try:\n",
    "        discard.append(row.split('/')[0])\n",
    "        keep.append(row.split('/')[1])\n",
    "    except:\n",
    "        print(\"Error during splitting\")\n",
    "        \n",
    "keep_df=pd.DataFrame(keep,columns=['locat'])\n",
    "\n",
    "lat=[]\n",
    "lon=[]\n",
    "\n",
    "for row in keep_df['locat']:\n",
    "    try:\n",
    "        lat.append(row.split('N')[0])\n",
    "        lon.append(row.split('N')[1])\n",
    "    except:\n",
    "        print('No Joy')\n",
    "\n",
    "df_bigcities['Latitude']=lat\n",
    "df_bigcities['Longitude']=lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_bigcities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0396e74ceee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_bigcities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Latitude'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_bigcities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Latitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'°'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_bigcities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Longitude'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_bigcities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Longitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'°E'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_bigcities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Latitude'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_bigcities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Latitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_bigcities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Latitude'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_bigcities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Latitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\ufeff'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_bigcities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Longitude'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_bigcities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Longitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_bigcities' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_bigcities['Latitude'] = df_bigcities['Latitude'].str.replace('°','')\n",
    "df_bigcities['Longitude'] = df_bigcities['Longitude'].str.replace('°E','')\n",
    "df_bigcities['Latitude'] = df_bigcities['Latitude'].str.replace(' ','')\n",
    "df_bigcities['Latitude'] = df_bigcities['Latitude'].str.replace('\\ufeff','')\n",
    "df_bigcities['Longitude'] = df_bigcities['Longitude'].str.replace(' ','')\n",
    "df_bigcities['Longitude'][2] = \"-0.1275\"\n",
    "df_bigcities['Longitude'][5] = \"-3.716667\"\n",
    "df_bigcities=df_bigcities.drop(columns=['Location'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigcities['Latitude']=df_bigcities.Latitude.astype(float)\n",
    "df_bigcities['Longitude']=df_bigcities.Longitude.astype(float)\n",
    "df_bigcities.dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_bigcities = folium.Map(location=[54.54, 25.19], zoom_start=4)\n",
    "for lat, lng, city, country in zip(df_bigcities['Latitude'], df_bigcities['Longitude'], df_bigcities['City'], df_bigcities['Country']):\n",
    "    label = '{}, {}'.format(city, country)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_bigcities) \n",
    "\n",
    "map_bigcities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'QRY31Y2XVZC3RCNJEX3FUROCNZ3VX5X15GAXR3STYVN1SERH' \n",
    "CLIENT_SECRET = 'ROFNZQUDFCHYJJBNPM00MHYNBRKCXEU33DLIYTT2ZBRN2I5U'\n",
    "VERSION = '20180605'\n",
    "\n",
    "LIMIT = 10000\n",
    "Radius = 250\n",
    "def getNearbyVenues(names, latitudes, longitudes, radius=250):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        \n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}&intent=browse&sortByPopularity=1'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng,\n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        \n",
    "\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']        \n",
    "        \n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng,\n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],\n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['City', \n",
    "                  'City Latitude', \n",
    "                  'City Longitude', \n",
    "                  'Venue',          \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude',\n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)\n",
    "\n",
    "venueseu = getNearbyVenues(names=df_bigcities['City'],\n",
    "                                   latitudes=df_bigcities['Latitude'],\n",
    "                                   longitudes=df_bigcities['Longitude'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues_onehot = pd.get_dummies(venueseu[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "venues_onehot['City'] = venueseu['City'] \n",
    "fixed_columns = [venues_onehot.columns[-1]] + list(venues_onehot.columns[:-1])\n",
    "venues_onehot = venues_onehot[fixed_columns]\n",
    "\n",
    "venues_grouped = venues_onehot.groupby('City').mean().reset_index()\n",
    "\n",
    "num_top_venues = 5\n",
    "\n",
    "for city in venues_grouped['City']:\n",
    "    print(\"----\"+city+\"----\")\n",
    "    temp = venues_grouped[venues_grouped['City'] == city].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]\n",
    "\n",
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "columns = ['City']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "cities_venues_sorted = pd.DataFrame(columns=columns)\n",
    "cities_venues_sorted['City'] =  venues_grouped['City']\n",
    "\n",
    "for ind in np.arange(venues_grouped.shape[0]):\n",
    "    cities_venues_sorted.iloc[ind, 1:] = return_most_common_venues(venues_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "cities_venues_sorted.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
